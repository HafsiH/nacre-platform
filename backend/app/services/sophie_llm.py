import json
import os
import time
from typing import Any, Dict, List, Optional
import re

from openai import OpenAI

from ..config import settings, GPT5_MODELS, GPT5_PARAMS
from .embeddings import index_status, retrieve_with_embeddings
from .nacre_dict import get_nacre_dict
from .patterns import _load as _load_patterns
from .document_access import sophie_get_context, get_document_access
from .natural_communication import natural_communication
from .co2_analyzer import co2_analyzer
import pandas as pd


MEM_PATH = os.path.join(settings.storage_dir, "db", "sophie_memory.json")


def _client() -> Optional[OpenAI]:
    if not settings.openai_api_key:
        return None
    try:
        return OpenAI(api_key=settings.openai_api_key)
    except Exception:
        return None


def _load_memory() -> Dict[str, Any]:
    os.makedirs(os.path.join(settings.storage_dir, "db"), exist_ok=True)
    if not os.path.exists(MEM_PATH):
        return {"created_at": time.time(), "events": [], "chat": []}
    try:
        with open(MEM_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"created_at": time.time(), "events": [], "chat": []}


def _save_memory(mem: Dict[str, Any]):
    with open(MEM_PATH, "w", encoding="utf-8") as f:
        json.dump(mem, f, ensure_ascii=False)


def _sophie_query_nacre_dictionary(query: str, top_k: int = 10) -> Dict[str, Any]:
    """Allow Sophie to directly query the NACRE dictionary with emissions data"""
    try:
        # Get NACRE dictionary
        nacre_dict = get_nacre_dict()
        
        # Load CO2 emissions data
        co2_data = co2_analyzer.emission_data if co2_analyzer.emission_data is not None else pd.DataFrame()
        
        # Use embeddings for semantic search
        enriched = retrieve_with_embeddings(query, top_k=top_k)
        
        results = []
        if enriched:
            for item in enriched:
                code = item.get("code", "")
                category = item.get("category", "")
                
                # Get emission data if available
                emission_info = None
                if not co2_data.empty:
                    matches = co2_data[co2_data['code_nacre'] == code]
                    if not matches.empty:
                        entry = matches.iloc[0]
                        emission_value = entry.get('emission')
                        emission_factor_value = entry.get('emission_factor')
                        
                        if pd.notna(emission_value) and float(emission_value) > 0:
                            emission_info = {
                                "value": float(emission_value),
                                "source": "emission",
                                "unit": "kg CO2/‚Ç¨"
                            }
                        elif pd.notna(emission_factor_value) and float(emission_factor_value) > 0:
                            emission_info = {
                                "value": float(emission_factor_value),
                                "source": "emission_factor", 
                                "unit": "kg CO2/‚Ç¨"
                            }
                
                results.append({
                    "code": code,
                    "category": category,
                    "keywords": item.get("keywords", []),
                    "emission": emission_info,
                    "confidence": item.get("confidence", 0)
                })
        
        return {
            "query": query,
            "total_results": len(results),
            "results": results,
            "nacre_dict_entries": len(nacre_dict.entries) if hasattr(nacre_dict, 'entries') else 0,
            "co2_data_loaded": not co2_data.empty,
            "co2_entries": len(co2_data) if not co2_data.empty else 0
        }
        
    except Exception as e:
        return {
            "query": query,
            "error": str(e),
            "results": []
        }


def _sophie_find_highest_emission_codes(top_n: int = 10) -> Dict[str, Any]:
    """Find NACRE codes with highest CO2 emissions"""
    try:
        co2_data = co2_analyzer.emission_data if co2_analyzer.emission_data is not None else pd.DataFrame()
        
        if co2_data.empty:
            return {"error": "Donn√©es d'√©missions CO2 non disponibles"}
        
        # Sort by emission values (prioritize 'emission' over 'emission_factor')
        results = []
        
        for _, row in co2_data.iterrows():
            code = row.get('code_nacre', '')
            description = row.get('description', '')
            emission_value = row.get('emission')
            emission_factor_value = row.get('emission_factor')
            
            # Determine which emission value to use
            if pd.notna(emission_value) and float(emission_value) > 0:
                emission = float(emission_value)
                source = "emission"
            elif pd.notna(emission_factor_value) and float(emission_factor_value) > 0:
                emission = float(emission_factor_value)
                source = "emission_factor"
            else:
                continue
                
            results.append({
                "code": code,
                "description": description,
                "emission_value": emission,
                "source": source,
                "unit": "kg CO2/‚Ç¨"
            })
        
        # Sort by emission value descending
        results.sort(key=lambda x: x["emission_value"], reverse=True)
        
        return {
            "top_emitters": results[:top_n],
            "total_codes_with_emissions": len(results),
            "highest_emission": results[0]["emission_value"] if results else 0,
            "source_breakdown": {
                "emission": len([r for r in results if r["source"] == "emission"]),
                "emission_factor": len([r for r in results if r["source"] == "emission_factor"])
            }
        }
        
    except Exception as e:
        return {"error": str(e)}


def _sophie_get_code_details(code: str) -> Dict[str, Any]:
    """Get detailed information about a specific NACRE code"""
    try:
        nacre_dict = get_nacre_dict()
        co2_data = co2_analyzer.emission_data if co2_analyzer.emission_data is not None else pd.DataFrame()
        
        # Find in NACRE dictionary
        nacre_info = None
        if hasattr(nacre_dict, 'entries'):
            for entry in nacre_dict.entries:
                if entry.code == code:
                    nacre_info = {
                        "code": entry.code,
                        "category": entry.category,
                        "keywords": getattr(entry, 'keywords', [])
                    }
                    break
        
        # Find emission data
        emission_info = None
        if not co2_data.empty:
            matches = co2_data[co2_data['code_nacre'] == code]
            if not matches.empty:
                entry = matches.iloc[0]
                emission_value = entry.get('emission')
                emission_factor_value = entry.get('emission_factor')
                
                if pd.notna(emission_value) and float(emission_value) > 0:
                    emission_info = {
                        "value": float(emission_value),
                        "source": "emission",
                        "unit": "kg CO2/‚Ç¨",
                        "description": entry.get('description', '')
                    }
                elif pd.notna(emission_factor_value) and float(emission_factor_value) > 0:
                    emission_info = {
                        "value": float(emission_factor_value),
                        "source": "emission_factor",
                        "unit": "kg CO2/‚Ç¨",
                        "description": entry.get('description', '')
                    }
        
        return {
            "code": code,
            "found": nacre_info is not None or emission_info is not None,
            "nacre_info": nacre_info,
            "emission_info": emission_info
        }
        
    except Exception as e:
        return {
            "code": code,
            "error": str(e),
            "found": False
        }


def sophie_add_event(event_type: str, payload: Dict[str, Any]):
    mem = _load_memory()
    events: List[Dict[str, Any]] = mem.get("events", [])
    events.append({"ts": time.time(), "type": event_type, "data": payload})
    mem["events"] = events[-1000:]
    _save_memory(mem)


def sophie_clear_memory():
    _save_memory({"created_at": time.time(), "events": [], "chat": []})


def sophie_status() -> Dict[str, Any]:
    mem = _load_memory()
    return {
        "name": "Sophie",
        "model": settings.sophie_model,
        "events": len(mem.get("events", [])),
        "enabled": settings.sophie_enabled,
    }


def sophie_generate_message(kind: str, context: Dict[str, Any]) -> str:
    """Enhanced greeting/brief message for Sophie with GPT-5 capabilities."""
    system = (
        "Tu es Sophie, IA assistante experte pour le bilan carbone et la classification NACRE.\n\n"
        "CAPACIT√âS:\n"
        "- Acc√®s complet au dictionnaire NACRE (1571+ codes)\n"
        "- IA - Analyse CO2 int√©gr√©e pour calculs de bilan carbone\n"
        "- Analyse des patterns d'apprentissage (fournisseurs, comptes)\n"
        "- Historique des conversions et erreurs\n"
        "- Expertise en classification automatique\n\n"
        "R√îLE: Guider, diagnostiquer, proposer des actions concr√®tes.\n"
        "STYLE: Toujours en fran√ßais, style professionnel et technique.\n"
        "CONTRAINTES: Pas de cha√Æne de pens√©e d√©taill√©e; fournir des synth√®ses et puces factuelles.\n"
        "FORMAT: a) paragraphe bref, b) 2-4 puces, c) Action(s)."
    )
    if kind == "greeting":
        user = (
            "Bonjour, presente‚Äëtoi et explique en 2 phrases: 1) que tu vas d‚Äôabord identifier les classifications NACRE des achats; "
            f"2) que le dictionnaire NACRE contient {context.get('dict_lines', 0)} lignes et qu‚Äôun apprentissage est {('en cours' if context.get('learning_in_progress') else 'pret')}. "
            "Mentionne que Sophie orchestre plusieurs IA (classification, apprentissage, analyse). Reste tres court."
        )
    else:
        user = context.get("prompt", "Fais un court recapitulatif en une phrase.")

    client = _client() if settings.sophie_enabled else None
    if client is None:
        status = "en cours" if context.get("learning_in_progress") else "pr√™t"
        dict_lines = context.get('dict_lines', 1571)
        
        return (
            f"ü§ñ **Bonjour ! Je suis Sophie, votre IA assistante agentique NACRE**\n\n"
            f"**üéØ Mission :** Optimiser vos classifications NACRE avec intelligence autonome\n"
            f"**üìä Ressources :** {dict_lines:,} codes NACRE analys√©s ‚Ä¢ Apprentissage {status}\n"
            f"**üß† Capacit√©s :** Analyse contextuelle ‚Ä¢ Recommandations proactives ‚Ä¢ Orchestration multi-IA\n\n"
            f"**Mes actions agentiques √† votre service :**\n"
            f"‚Ä¢ Classification intelligente de vos achats\n"
            f"‚Ä¢ D√©tection automatique d'anomalies\n"
            f"‚Ä¢ Recommandations d'optimisation personnalis√©es\n"
            f"‚Ä¢ Apprentissage continu de vos patterns\n\n"
            f"üí° **Comment puis-je vous aider ?** D√©crivez un achat, posez une question technique, ou demandez une analyse !"
        )

    try:
        resp = client.chat.completions.create(
            model=GPT5_MODELS["orchestrator"],
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            **GPT5_PARAMS["orchestrator"]
        )
        content = resp.choices[0].message.content or ""
        return content.strip()
    except Exception:
        status = "en cours" if context.get("learning_in_progress") else "pr√™t"
        dict_lines = context.get('dict_lines', 1571)
        
        return (
            f"ü§ñ **Bonjour ! Je suis Sophie, votre IA assistante agentique NACRE**\n\n"
            f"**üéØ Mission :** Optimiser vos classifications NACRE avec intelligence autonome\n"
            f"**üìä Ressources :** {dict_lines:,} codes NACRE analys√©s ‚Ä¢ Apprentissage {status}\n"
            f"**üß† Capacit√©s :** Analyse contextuelle ‚Ä¢ Recommandations proactives ‚Ä¢ Orchestration multi-IA\n\n"
            f"**Mes actions agentiques √† votre service :**\n"
            f"‚Ä¢ Classification intelligente de vos achats\n"
            f"‚Ä¢ D√©tection automatique d'anomalies\n"
            f"‚Ä¢ Recommandations d'optimisation personnalis√©es\n"
            f"‚Ä¢ Apprentissage continu de vos patterns\n\n"
            f"üí° **Comment puis-je vous aider ?** D√©crivez un achat, posez une question technique, ou demandez une analyse !"
        )


def sophie_chat(user_message: str) -> Dict[str, Any]:
    """Enhanced agentic chat with Sophie using GPT-5. Builds comprehensive context and provides intelligent responses with chain-of-thought reasoning and task management."""
    try:
        mem = _load_memory()
        d = get_nacre_dict()
        learn = index_status()
        patterns = _load_patterns()

        # Enhanced context gathering with document access
        doc_context = sophie_get_context()
        last_events = mem.get("events", [])[-10:]  # Increased from 5 to 10
        convs = [e for e in last_events if e.get("type") == "conversion_completed"]
        total_lines = sum(e.get("data", {}).get("total", 0) for e in convs)
        total_errors = sum(e.get("data", {}).get("stats", {}).get("errors", 0) for e in convs)

        # Enhanced snapshot with comprehensive document information
        snapshot = (
            f"DICTIONNAIRE NACRE: {doc_context['nacre_dictionary']['total_entries']} entr√©es ({doc_context['nacre_dictionary']['categories_count']} cat√©gories); "
            f"APPRENTISSAGE: {'en cours' if doc_context['embeddings']['in_progress'] else ('pr√™t' if doc_context['embeddings']['ready'] else 'indisponible')} "
            f"(mod√®le: {doc_context['embeddings']['model']}); "
            f"CONVERSIONS R√âCENTES: {len(convs)} (lignes: {total_lines}, erreurs: {total_errors}); "
            f"DONN√âES D'ENTRA√éNEMENT: {doc_context['training_data']['total_training_items']} √©l√©ments "
            f"({doc_context['training_data']['unique_codes']} codes, {doc_context['training_data']['unique_suppliers']} fournisseurs, {doc_context['training_data']['unique_accounts']} comptes); "
            f"PATRONS APPRIS: {doc_context['patterns']['suppliers_count']} fournisseurs, {doc_context['patterns']['accounts_count']} comptes."
        )

        # Retrieve doc-grounded snippets: related NACRE codes + training examples
        doc = get_document_access()
        related_codes = doc.search_nacre_codes(user_message, limit=5)
        related_examples = doc.search_training_examples(user_message, limit=5)

        codes_str = "\n".join([f"- {c['code']} ¬∑ {c['category']}" for c in related_codes]) or "(aucun)"
        ex_str = "\n".join([
            f"- label='{e.get('label','')}', code={e.get('code','')}, fournisseur={ (e.get('context',{}) or {}).get('fournisseur','') }, compte={ (e.get('context',{}) or {}).get('compte','') }"
            for e in related_examples
        ]) or "(aucun)"

        # Detect intents
        def _normalize_text(t: str) -> str:
            try:
                import unicodedata
                t = unicodedata.normalize('NFKD', t)
                t = ''.join(c for c in t if not unicodedata.combining(c))
            except Exception:
                pass
            return (t or "").lower().strip()

        norm_msg = _normalize_text(user_message)
        
        # Enhanced intent detection for direct NACRE queries
        highest_emission_query = any(word in norm_msg for word in ["plus grand", "highest", "maximum", "plus √©lev√©", "plus fort"]) and any(word in norm_msg for word in ["emission", "facteur", "co2", "carbone"])
        code_details_query = re.search(r'\b[A-Z]{2}\.[0-9]{2}\b', user_message)  # Pattern like AA.21
        search_query = any(word in norm_msg for word in ["quel", "que", "correspond", "signifie", "categorie", "description"])
        
        # Handle direct NACRE queries first
        if highest_emission_query:
            emission_data = _sophie_find_highest_emission_codes(top_n=5)
            if "error" not in emission_data:
                top_codes = emission_data["top_emitters"]
                response = f"**Codes NACRE avec les plus hauts facteurs d'√©mission CO2 :**\n\n"
                for i, code_info in enumerate(top_codes, 1):
                    response += f"{i}. **{code_info['code']}** - {code_info['description']}\n"
                    response += f"   ‚Ä¢ √âmission : {code_info['emission_value']:.4f} {code_info['unit']}\n"
                    response += f"   ‚Ä¢ Source : {code_info['source']}\n\n"
                
                response += f"üìä **Statistiques :**\n"
                response += f"‚Ä¢ Total des codes avec √©missions : {emission_data['total_codes_with_emissions']}\n"
                response += f"‚Ä¢ √âmission maximale : {emission_data['highest_emission']:.4f} kg CO2/‚Ç¨\n"
                
                return {
                    "reply": response,
                    "confidence": 0.95,
                    "source": "direct_nacre_query",
                    "data_used": emission_data
                }
        
        elif code_details_query:
            code = code_details_query.group(0)
            code_info = _sophie_get_code_details(code)
            if code_info.get("found"):
                response = f"**Code NACRE {code} :**\n\n"
                if code_info.get("nacre_info"):
                    response += f"‚Ä¢ **Cat√©gorie :** {code_info['nacre_info']['category']}\n"
                if code_info.get("emission_info"):
                    response += f"‚Ä¢ **Description :** {code_info['emission_info']['description']}\n"
                    response += f"‚Ä¢ **Facteur d'√©mission :** {code_info['emission_info']['value']:.4f} {code_info['emission_info']['unit']}\n"
                    response += f"‚Ä¢ **Source :** {code_info['emission_info']['source']}\n"
                else:
                    response += "‚Ä¢ Aucune donn√©e d'√©mission CO2 disponible\n"
                
                return {
                    "reply": response,
                    "confidence": 0.90,
                    "source": "direct_code_lookup",
                    "data_used": code_info
                }
            else:
                response = f"**Code NACRE {code} non trouv√©** dans la base de donn√©es."
                if "error" in code_info:
                    response += f"\n\nErreur : {code_info['error']}"
                return {
                    "reply": response,
                    "confidence": 0.80,
                    "source": "direct_code_lookup",
                    "data_used": code_info
                }
        
        elif search_query and len(user_message) > 10:
            # Use semantic search for general NACRE queries
            search_results = _sophie_query_nacre_dictionary(user_message, top_k=5)
            if search_results.get("results"):
                response = f"**Recherche dans le dictionnaire NACRE :**\n\n"
                response += f"*Requ√™te : {user_message}*\n\n"
                
                for i, result in enumerate(search_results["results"][:3], 1):
                    response += f"{i}. **{result['code']}** - {result['category']}\n"
                    if result.get("emission"):
                        response += f"   ‚Ä¢ CO2 : {result['emission']['value']:.4f} {result['emission']['unit']}\n"
                    response += f"   ‚Ä¢ Confiance : {result.get('confidence', 0):.2f}\n\n"
                
                response += f"üìä {search_results['total_results']} r√©sultats trouv√©s sur {search_results['nacre_dict_entries']} entr√©es NACRE\n"
                
                return {
                    "reply": response,
                    "confidence": 0.85,
                    "source": "semantic_nacre_search",
                    "data_used": search_results
                }
        
        access_re = re.compile(r"\bacc?e?ss?\b")
        is_access_query = (
            (bool(access_re.search(norm_msg)) or "acc√®s" in norm_msg or "as tu" in norm_msg or "as-tu" in norm_msg or "tu as" in norm_msg)
            and ("diction" in norm_msg or "dictionary" in norm_msg or "nacre" in norm_msg or "dico" in norm_msg)
        )
        is_code_query = (
            ("code nacre" in norm_msg) or
            ("quel" in norm_msg and ("code" in norm_msg or "nacre" in norm_msg)) or
            ("which" in norm_msg and ("code" in norm_msg and "nacre" in norm_msg)) or
            bool(re.search(r"\bcode\b.*\bnacre\b", norm_msg))
        )
        is_concept_query = (
            ("qu'est ce que" in norm_msg or "c'est quoi" in norm_msg or "explique" in norm_msg or "concept" in norm_msg) and "nacre" in norm_msg
        )
        # Handle NACRE concept explanation deterministically
        if is_concept_query:
            reply = (
                "Le code NACRE est une nomenclature utilis√©e pour classer et cat√©goriser les natures d'achats et de d√©penses. "
                "Chaque code identifie un type d'achat (ex: fournitures de bureau, mobilier, maintenance, logiciels) afin de faciliter l'analyse, la consolidation et le reporting.\n\n"
                "- Finalit√©: normaliser les libell√©s et regrouper les d√©penses par cat√©gorie homog√®ne.\n"
                "- Usage: conversion automatique des lignes (libell√©/fournisseur/compte) vers un code.\n"
                "- B√©n√©fice: meilleure coh√©rence, suivi, et optimisation des analyses (ex: bilan carbone, pilotage achats).\n\n"
                "Exemple: ‚ÄòPapeterie / fournitures de bureau‚Äô ‚Üí code NACRE AB.01 (Petites fournitures et petits √©quipements de bureau)."
            )
            chats = mem.get("chat", [])
            ts = time.time()
            chats.append({"ts": ts, "role": "user", "content": user_message})
            chats.append({"ts": ts, "role": "assistant", "content": reply})
            mem["chat"] = chats[-200:]
            mem["last_debug"] = {
                "received": True,
                "interpreted": True,
                "used_fallback": True,
                "has_conversions": bool(convs),
                "snapshot": snapshot,
                "model_used": GPT5_MODELS["orchestrator"],
                "deterministic_concept_answer": True,
            }
            _save_memory(mem)
            return {"reply": reply}

        # Handle dictionary access questions deterministically
        if is_access_query:
            nd = doc_context['nacre_dictionary']
            entries = nd.get('total_entries', 0)
            cats = nd.get('categories_count', 0)
            reply = (
                "Oui ‚Äî j'ai acc√®s complet au dictionnaire NACRE.\n\n"
                f"- Entr√©es: {entries}\n"
                f"- Cat√©gories: {cats}\n"
                "- Je peux rechercher des codes et expliquer chaque entr√©e.\n\n"
                "Posez une question comme: ‚ÄòQuel code NACRE pour la papeterie ?‚Äô ou ‚ÄòTrouve le code pour la maintenance serveur‚Äô."
            )
            chats = mem.get("chat", [])
            ts = time.time()
            chats.append({"ts": ts, "role": "user", "content": user_message})
            chats.append({"ts": ts, "role": "assistant", "content": reply})
            mem["chat"] = chats[-200:]
            mem["last_debug"] = {
                "received": True,
                "interpreted": True,
                "used_fallback": True,
                "has_conversions": bool(convs),
                "snapshot": snapshot,
                "model_used": GPT5_MODELS["orchestrator"],
                "deterministic_access_answer": True,
            }
            _save_memory(mem)
            return {"reply": reply}

        # If code-lookup intent: rank candidates deterministically and answer directly
        if is_code_query:
            # Aggregate scores from dictionary search and training examples
            candidate_scores: Dict[str, int] = {}
            code_to_category: Dict[str, str] = {}
            for c in related_codes:
                code = (c.get('code') or '').upper()
                if not code:
                    continue
                candidate_scores[code] = candidate_scores.get(code, 0) + int(c.get('score', 0))
                code_to_category[code] = c.get('category') or code_to_category.get(code, '')
            for ex in related_examples:
                code = (ex.get('code') or '').upper()
                if not code:
                    continue
                candidate_scores[code] = candidate_scores.get(code, 0) + 10  # weight examples strongly

            ranked = sorted(candidate_scores.items(), key=lambda kv: kv[1], reverse=True)
            if ranked:
                top = ranked[:3]
                lines = []
                for code, score in top:
                    cat = code_to_category.get(code, '')
                    if cat:
                        lines.append(f"- {code} ¬∑ {cat}")
                    else:
                        lines.append(f"- {code}")
                reply = (
                    "R√©ponse directe (depuis le dictionnaire et l'entrainement):\n"
                    f"Code le plus probable: {top[0][0]}\n"
                    f"Autres candidats:\n" + "\n".join(lines)
                )
                # Record and return immediately
                chats = mem.get("chat", [])
                ts = time.time()
                chats.append({"ts": ts, "role": "user", "content": user_message})
                chats.append({"ts": ts, "role": "assistant", "content": reply})
                mem["chat"] = chats[-200:]
                mem["last_debug"] = {
                    "received": True,
                    "interpreted": True,
                    "used_fallback": True,
                    "has_conversions": bool(convs),
                    "snapshot": snapshot,
                    "model_used": GPT5_MODELS["orchestrator"],
                    "deterministic_code_answer": True,
                }
                _save_memory(mem)
                return {"reply": reply}

        # Enhanced system prompt for GPT-5
        system = (
            "Tu es Sophie, IA assistante experte pour le bilan carbone et la classification NACRE.\n\n"
            "CAPACIT√âS:\n"
            "- Acc√®s complet au dictionnaire NACRE (1571+ codes)\n"
            "- Analyse des patterns d'apprentissage (fournisseurs, comptes)\n"
            "- Historique des conversions et erreurs\n"
            "- Expertise en classification automatique\n\n"
            "R√îLE: Analyser le contexte, d√©tecter les signaux, conseiller des actions pr√©cises.\n"
            "STYLE: R√©ponse structur√©e en fran√ßais: 1) paragraphe synth√©tique, 2) 2-4 puces factuelles, 3) Action(s) concr√®te(s).\n"
            "CONTRAINTES: Pas de cha√Æne de pens√©e d√©taill√©e; fournir des explications courtes et s√ªres.\n"
            "IMPORTANT: Tu as un acc√®s direct au dictionnaire NACRE local (entr√©e par entr√©e). Ne dis jamais que tu n'y as pas acc√®s.\n\n"
            "CONTEXTE DISPONIBLE:\n"
            f"{snapshot}"
        )
        
        # Enhanced user prompt with better structure + RAG snippets
        user = (
            f"CONTEXTE SYST√àME:\n{snapshot}\n\n"
            f"QUESTION UTILISATEUR: {user_message}\n\n"
            "EXEMPLES ET CODES LI√âS AU CONTENU:\n"
            f"Codes proches:\n{codes_str}\n"
            f"Exemples d'entrainement pertinents:\n{ex_str}\n\n"
            "INSTRUCTIONS: Analyse la question et fournis une r√©ponse structur√©e:\n"
            "1. Paragraphe synth√©tique (2-3 phrases)\n"
            "2. 2-4 puces d'observations factuelles\n"
            "3. Action(s) concr√®te(s) √† entreprendre\n"
            "R√©ponds en fran√ßais, style professionnel et technique."
        )

        # Detect explicit literal instruction
        literal: Optional[str] = None
        m = re.search(r"respond\s+by\s+saying\s+'([^']+)'", user_message, re.IGNORECASE)
        if not m:
            m = re.search(r"r[e√©]pond.*?\s+'([^']+)'", user_message, re.IGNORECASE)
        if m:
            literal = m.group(1)

        client = _client() if settings.sophie_enabled else None
        used_fallback = False
        interpreted = True
        
        if literal is not None:
            reply = literal
        elif client is None:
            # Enhanced agentic fallback using retrieved snippets
            reply = _generate_agentic_response(user_message, snapshot, codes_str, ex_str, doc_context)
            used_fallback = True
        else:
            try:
                resp = client.chat.completions.create(
                        model=GPT5_MODELS["orchestrator"],
                    messages=[
                            {"role": "system", "content": system + "\nPriorit√© GPT-5: respecter toute instruction explicite tout en appliquant un raisonnement avanc√©."},
                        {"role": "user", "content": user},
                    ],
                        **GPT5_PARAMS["orchestrator"]
                )
                reply = (resp.choices[0].message.content or "").strip()
            except Exception as e:
                # Enhanced agentic fallback using retrieved snippets even if API call fails
                reply = _generate_agentic_response(user_message, snapshot, codes_str, ex_str, doc_context)
                used_fallback = True

        chats = mem.get("chat", [])
        ts = time.time()
        chats.append({"ts": ts, "role": "user", "content": user_message})
        chats.append({"ts": ts, "role": "assistant", "content": reply})
        mem["chat"] = chats[-200:]
        mem["last_debug"] = {
            "received": True,
            "interpreted": interpreted,
            "used_fallback": used_fallback,
            "has_conversions": bool(convs),
            "snapshot": snapshot,
                "model_used": GPT5_MODELS["orchestrator"],
        }
        _save_memory(mem)
        return {"reply": reply}
    except Exception as e:
        # Return fallback response if chat fails
        return {
            "reply": f"D√©sol√©, je ne peux pas traiter votre message pour le moment. Erreur: {str(e)}",
            "error": True
        }


def sophie_chat_history(limit: int = 50) -> List[Dict[str, Any]]:
    mem = _load_memory()
    return (mem.get("chat", []) or [])[-limit:]


def _generate_agentic_response(user_message: str, snapshot: str, codes_str: str, ex_str: str, doc_context: Dict[str, Any]) -> str:
    """Generate intelligent agentic response when GPT models are unavailable"""
    
    # Analyze user intent with pattern matching
    msg_lower = user_message.lower()
    
    # Determine response type based on user intent
    if any(word in msg_lower for word in ["test", "hello", "bonjour", "salut"]):
        return _generate_greeting_response(doc_context)
    elif any(word in msg_lower for word in ["code", "classification", "nacre"]):
        return _generate_classification_response(user_message, codes_str, ex_str)
    elif any(word in msg_lower for word in ["analyse", "tendance", "statistique", "rapport"]):
        return _generate_analysis_response(user_message, snapshot, doc_context)
    elif any(word in msg_lower for word in ["aide", "help", "comment", "utiliser"]):
        return _generate_help_response()
    elif any(word in msg_lower for word in ["probl√®me", "erreur", "bug", "issue"]):
        return _generate_troubleshooting_response(user_message, snapshot)
    else:
        return _generate_general_response(user_message, codes_str, ex_str, snapshot)

def _generate_greeting_response(doc_context: Dict[str, Any]) -> str:
    """Generate agentic greeting response"""
    dict_entries = doc_context.get('nacre_dictionary', {}).get('total_entries', 1571)
    embeddings_ready = doc_context.get('embeddings', {}).get('ready', False)
    embeddings_status = "üü¢ Op√©rationnel" if embeddings_ready else "üü° En cours d'initialisation"
    
    return (
        "ü§ñ **Bonjour ! Je suis Sophie, votre IA assistante agentique NACRE**\n\n"
        "**üìä √âtat du syst√®me :**\n"
        f"‚Ä¢ Dictionnaire NACRE : {dict_entries:,} codes analys√©s et pr√™ts\n"
        f"‚Ä¢ Moteur d'embeddings : {embeddings_status}\n"
        "‚Ä¢ Capacit√©s agentiques : üü¢ Pleinement actives\n\n"
        "**üéØ Mes capacit√©s agentiques √† votre service :**\n"
        "‚Ä¢ **Analyse intelligente** : Je comprends vos besoins et agis de mani√®re autonome\n"
        "‚Ä¢ **Classification proactive** : Je trouve les meilleurs codes NACRE pour vos achats\n"
        "‚Ä¢ **D√©tection d'anomalies** : J'identifie les incoh√©rences et propose des corrections\n"
        "‚Ä¢ **Recommandations strat√©giques** : Je vous guide vers l'optimisation de vos processus\n\n"
        "**üí° Comment puis-je vous aider ?**\n"
        "‚Ä¢ D√©crivez un achat : *\"ordinateur portable Dell\"*\n"
        "‚Ä¢ Demandez une analyse : *\"Quelles sont mes tendances d'achat IT ?\"*\n"
        "‚Ä¢ Posez une question technique : *\"Comment am√©liorer ma pr√©cision de classification ?\"*\n\n"
        "Je suis pr√™te √† agir de mani√®re autonome pour optimiser vos classifications NACRE ! üöÄ"
    )

def _generate_classification_response(user_message: str, codes_str: str, ex_str: str) -> str:
    """Generate agentic classification response"""
    if not codes_str or codes_str == "(aucun)":
        return (
            f"ü§ñ **Analyse agentique de votre demande de classification**\n\n"
            f"**Question analys√©e :** {user_message}\n\n"
            f"**üîç Diagnostic autonome :**\n"
            f"Je n'ai pas trouv√© de correspondances directes dans ma base de connaissances actuelle, mais en tant qu'IA agentique, je vais proc√©der √† une analyse plus approfondie.\n\n"
            f"**üéØ Actions agentiques recommand√©es :**\n"
            f"1. **Pr√©cisez votre demande** : Ajoutez des d√©tails (fournisseur, montant, contexte)\n"
            f"2. **Reformulation** : Essayez des termes alternatifs ou plus sp√©cifiques\n"
            f"3. **Exploration guid√©e** : Je peux vous proposer des cat√©gories proches\n\n"
            f"**üí° Exemples d'optimisation :**\n"
            f"‚Ä¢ Au lieu de : *\"mat√©riel\"* ‚Üí Essayez : *\"ordinateur portable Dell\"*\n"
            f"‚Ä¢ Au lieu de : *\"service\"* ‚Üí Essayez : *\"maintenance serveur informatique\"*\n\n"
            f"Reformulez votre demande et je proc√©derai √† une nouvelle analyse agentique ! üîÑ"
        )
    
    # Extract the first few codes for analysis
    codes_lines = codes_str.split('\n')[:5]
    best_codes = []
    for line in codes_lines:
        if '¬∑' in line and line.strip().startswith('-'):
            best_codes.append(line.strip()[2:])  # Remove "- " prefix
    
    return (
        f"ü§ñ **Analyse agentique de classification NACRE**\n\n"
        f"**Question analys√©e :** {user_message}\n\n"
        f"**üéØ Codes NACRE identifi√©s par mon analyse :**\n"
        + '\n'.join([f"‚Ä¢ {code}" for code in best_codes[:3]]) + "\n\n"
        f"**üß† Raisonnement agentique :**\n"
        f"J'ai analys√© votre demande en croisant :\n"
        f"‚Ä¢ Correspondance s√©mantique avec le dictionnaire NACRE\n"
        f"‚Ä¢ Patterns d'apprentissage de classifications similaires\n"
        f"‚Ä¢ Contexte m√©tier et coh√©rence des cat√©gories\n\n"
        f"**‚ö° Actions autonomes recommand√©es :**\n"
        f"1. **Validation prioritaire** : V√©rifiez le premier code propos√©\n"
        f"2. **Affinage contextuel** : Pr√©cisez le fournisseur si n√©cessaire\n"
        f"3. **Apprentissage continu** : Cette interaction am√©liore mes futures analyses\n\n"
        f"**üöÄ Souhaitez-vous que je :**\n"
        f"‚Ä¢ Analyse d'autres aspects de cette classification ?\n"
        f"‚Ä¢ Propose des codes alternatifs ?\n"
        f"‚Ä¢ Proc√®de √† une validation crois√©e ?"
    )

def _generate_analysis_response(user_message: str, snapshot: str, doc_context: Dict[str, Any]) -> str:
    """Generate agentic analysis response"""
    return (
        f"üìä **Analyse agentique de vos donn√©es NACRE**\n\n"
        f"**Demande analys√©e :** {user_message}\n\n"
        f"**üîç Diagnostic automatique du syst√®me :**\n"
        f"‚Ä¢ Dictionnaire NACRE : {doc_context.get('nacre_dictionary', {}).get('total_entries', 1571):,} entr√©es actives\n"
        f"‚Ä¢ Donn√©es d'entra√Ænement : {doc_context.get('training_data', {}).get('total_training_items', 0)} exemples\n"
        f"‚Ä¢ Patterns d√©tect√©s : {doc_context.get('patterns', {}).get('suppliers_count', 0)} fournisseurs analys√©s\n\n"
        f"**üß† Insights agentiques identifi√©s :**\n"
        f"‚Ä¢ **Couverture** : Votre base de donn√©es couvre un large spectre de classifications\n"
        f"‚Ä¢ **Qualit√©** : Le syst√®me d'apprentissage s'am√©liore continuellement\n"
        f"‚Ä¢ **Opportunit√©s** : Potentiel d'optimisation des processus de classification\n\n"
        f"**üéØ Recommandations strat√©giques autonomes :**\n"
        f"1. **Consolidation** : Harmoniser les classifications similaires\n"
        f"2. **Enrichissement** : Ajouter plus de contexte aux classifications ambigu√´s\n"
        f"3. **Automatisation** : Augmenter le niveau de confiance des classifications automatiques\n\n"
        f"**‚ö° Actions imm√©diates que je peux entreprendre :**\n"
        f"‚Ä¢ Analyser vos patterns de classification les plus fr√©quents\n"
        f"‚Ä¢ Identifier les anomalies dans vos donn√©es\n"
        f"‚Ä¢ Proposer des optimisations personnalis√©es\n\n"
        f"Quelle analyse sp√©cifique souhaitez-vous que je r√©alise en priorit√© ? üöÄ"
    )

def _generate_help_response() -> str:
    """Generate agentic help response"""
    return (
        f"ü§ñ **Guide d'utilisation de Sophie - IA Agentique NACRE**\n\n"
        f"**üéØ Mes capacit√©s agentiques principales :**\n\n"
        f"**1. Classification intelligente :**\n"
        f"‚Ä¢ D√©crivez votre achat : *\"maintenance serveur Dell\"*\n"
        f"‚Ä¢ J'analyse automatiquement et propose le meilleur code NACRE\n"
        f"‚Ä¢ Je justifie mes choix avec un raisonnement transparent\n\n"
        f"**2. Analyse proactive :**\n"
        f"‚Ä¢ *\"Analyse mes tendances d'achat IT\"*\n"
        f"‚Ä¢ *\"D√©tecte les anomalies dans mes classifications\"*\n"
        f"‚Ä¢ *\"Propose des optimisations de processus\"*\n\n"
        f"**3. Support technique autonome :**\n"
        f"‚Ä¢ *\"Comment am√©liorer la pr√©cision de mes classifications ?\"*\n"
        f"‚Ä¢ *\"Explique-moi le code NACRE IA.24\"*\n"
        f"‚Ä¢ *\"Quelles sont les meilleures pratiques ?\"*\n\n"
        f"**üß† Mon approche agentique :**\n"
        f"‚Ä¢ **Compr√©hension** : J'analyse votre contexte m√©tier\n"
        f"‚Ä¢ **Action** : Je propose des solutions concr√®tes\n"
        f"‚Ä¢ **Apprentissage** : Je m'am√©liore avec chaque interaction\n"
        f"‚Ä¢ **Proactivit√©** : J'anticipe vos besoins futurs\n\n"
        f"**üí° Conseils d'optimisation :**\n"
        f"‚Ä¢ Soyez sp√©cifique dans vos descriptions\n"
        f"‚Ä¢ Mentionnez le contexte (fournisseur, montant)\n"
        f"‚Ä¢ N'h√©sitez pas √† poser des questions de suivi\n\n"
        f"Que puis-je faire pour optimiser votre exp√©rience NACRE ? üöÄ"
    )

def _generate_troubleshooting_response(user_message: str, snapshot: str) -> str:
    """Generate agentic troubleshooting response"""
    return (
        f"üîß **Diagnostic agentique de probl√®me**\n\n"
        f"**Probl√®me signal√© :** {user_message}\n\n"
        f"**üîç Analyse automatique du syst√®me :**\n"
        f"‚Ä¢ Statut des services : Op√©rationnels\n"
        f"‚Ä¢ Base de donn√©es NACRE : Accessible\n"
        f"‚Ä¢ Moteur de classification : Actif\n\n"
        f"**üß† Diagnostic agentique :**\n"
        f"En tant qu'IA agentique, j'ai analys√© votre situation et identifi√© plusieurs pistes de r√©solution :\n\n"
        f"**üéØ Solutions autonomes propos√©es :**\n"
        f"1. **V√©rification contextuelle** : Assurez-vous que les informations sont compl√®tes\n"
        f"2. **Reformulation** : Essayez une approche diff√©rente ou plus sp√©cifique\n"
        f"3. **Validation crois√©e** : Je peux analyser le probl√®me sous plusieurs angles\n\n"
        f"**‚ö° Actions imm√©diates que je peux entreprendre :**\n"
        f"‚Ä¢ Analyser en d√©tail votre cas sp√©cifique\n"
        f"‚Ä¢ Proposer des alternatives de classification\n"
        f"‚Ä¢ Ajuster mes param√®tres pour mieux r√©pondre √† vos besoins\n\n"
        f"**üöÄ √âtapes de r√©solution recommand√©es :**\n"
        f"1. D√©crivez plus pr√©cis√©ment le probl√®me rencontr√©\n"
        f"2. Fournissez un exemple concret si possible\n"
        f"3. Je proc√©derai √† une analyse agentique approfondie\n\n"
        f"Pouvez-vous me donner plus de d√©tails pour que je puisse agir de mani√®re optimale ? üîç"
    )

def _generate_general_response(user_message: str, codes_str: str, ex_str: str, snapshot: str) -> str:
    """Generate general agentic response"""
    has_codes = codes_str and codes_str != "(aucun)"
    has_examples = ex_str and ex_str != "(aucun)"
    
    response = (
        f"ü§ñ **Analyse agentique de votre demande**\n\n"
        f"**Question trait√©e :** {user_message}\n\n"
        f"**üß† Analyse contextuelle autonome :**\n"
    )
    
    if has_codes:
        response += (
            f"J'ai identifi√© plusieurs codes NACRE pertinents dans ma base de connaissances :\n\n"
            f"**üìã Codes pertinents d√©tect√©s :**\n{codes_str}\n\n"
        )
    
    if has_examples:
        response += (
            f"**üìä Exemples d'apprentissage correspondants :**\n{ex_str}\n\n"
        )
    
    response += (
        f"**üéØ Recommandations agentiques :**\n"
        f"1. **Validation prioritaire** : Examinez les correspondances propos√©es ci-dessus\n"
        f"2. **Affinage contextuel** : Pr√©cisez votre demande si n√©cessaire pour une analyse plus fine\n"
        f"3. **Optimisation continue** : Cette interaction enrichit ma base d'apprentissage\n\n"
        f"**‚ö° Actions autonomes disponibles :**\n"
        f"‚Ä¢ Analyse approfondie d'un code sp√©cifique\n"
        f"‚Ä¢ Comparaison entre plusieurs options\n"
        f"‚Ä¢ Recommandations personnalis√©es selon votre contexte\n\n"
        f"**üöÄ Prochaines √©tapes sugg√©r√©es :**\n"
        f"Souhaitez-vous que je proc√®de √† une analyse plus d√©taill√©e d'un aspect particulier ? "
        f"Je peux agir de mani√®re autonome pour vous fournir des insights plus pr√©cis ! üí°"
    )
    
    return response

def sophie_chat_humanized(user_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict[str, Any]:
    """
    Communication humanis√©e avec Sophie utilisant GPT-5 mini pour la naturalit√©
    
    Args:
        user_message: Message de l'utilisateur
        conversation_history: Historique de conversation pour le contexte
        
    Returns:
        Dict contenant la r√©ponse humanis√©e et les m√©tadonn√©es
    """
    try:
        # 1. Obtenir la r√©ponse technique de Sophie
        technical_response = sophie_chat(user_message)
        
        # 2. Cr√©er le contexte enrichi pour l'humanisation
        context = {
            "conversation_history": conversation_history or [],
            "user_expertise": "auto_detected",
            "session_context": {
                "nacre_focus": True,
                "technical_assistance": True,
                "classification_support": True
            },
            "sophie_confidence": technical_response.get("confidence", 0.8),
            "technical_details": {
                "has_classification": "classification" in str(technical_response),
                "has_recommendations": "recommand" in str(technical_response).lower(),
                "has_analysis": "analys" in str(technical_response).lower()
            }
        }
        
        # 3. Humaniser la r√©ponse avec GPT-5 mini
        humanized_result = natural_communication.humanize_sophie_response(
            technical_response=str(technical_response.get("reply", "")),
            user_message=user_message,
            context=context
        )
        
        # 4. Am√©liorer la fluidit√© conversationnelle si historique disponible
        if conversation_history:
            humanized_result["humanized_text"] = natural_communication.enhance_conversation_flow(
                conversation_history=conversation_history,
                current_response=humanized_result["humanized_text"]
            )
        
        # 5. Retourner la r√©ponse enrichie
        return {
            **technical_response,  # Garder les donn√©es techniques originales
            "reply": humanized_result["humanized_text"],
            "communication_metadata": {
                "tone": humanized_result.get("tone", "natural"),
                "emotion": humanized_result.get("emotion", "helpful"),
                "confidence": humanized_result.get("confidence", 0.8),
                "personalization": humanized_result.get("personalization", {}),
                "humanization_success": humanized_result.get("success", True),
                "original_technical_reply": str(technical_response.get("reply", "")),
                "communication_model": GPT5_MODELS.get("communication", "gpt-4o-mini")
            }
        }
        
    except Exception as e:
        # Fallback vers r√©ponse technique en cas d'erreur
        fallback_response = sophie_chat(user_message)
        return {
            **fallback_response,
            "communication_metadata": {
                "tone": "technical",
                "emotion": "neutral", 
                "confidence": 0.5,
                "humanization_success": False,
                "error": str(e),
                "fallback_used": True
            }
        }

def sophie_chat_with_thinking(user_message: str) -> Dict[str, Any]:
    """Enhanced chat with chain-of-thought reasoning and task management"""
    try:
        # Initialize thinking process
        thinking_steps = []
        tasks_created = []
        tasks_completed = []
        
        # Step 1: Analyze user intent
        thinking_steps.append({
            "step": "Intent Analysis",
            "content": f"Analyzing user message: '{user_message}'",
            "status": "processing"
        })
        
        intent_analysis = _analyze_user_intent(user_message)
        thinking_steps[-1]["content"] += f"\nDetected intent: {intent_analysis['primary_intent']}"
        thinking_steps[-1]["status"] = "completed"
        
        # Step 2: Context gathering
        thinking_steps.append({
            "step": "Context Gathering",
            "content": "Gathering relevant context and data sources...",
            "status": "processing"
        })
        
        context = _gather_comprehensive_context()
        thinking_steps[-1]["content"] += f"\nGathered: {context['sources_count']} data sources, {context['nacre_codes']} NACRE codes available"
        thinking_steps[-1]["status"] = "completed"
        
        # Step 3: Task planning
        thinking_steps.append({
            "step": "Task Planning",
            "content": "Planning autonomous tasks based on user request...",
            "status": "processing"
        })
        
        planned_tasks = _plan_autonomous_tasks(user_message, intent_analysis)
        tasks_created.extend(planned_tasks)
        thinking_steps[-1]["content"] += f"\nPlanned {len(planned_tasks)} autonomous tasks"
        thinking_steps[-1]["status"] = "completed"
        
        # Step 4: Execute tasks
        for task in planned_tasks:
            thinking_steps.append({
                "step": f"Executing: {task['name']}",
                "content": f"Running task: {task['description']}",
                "status": "processing"
            })
            
            task_result = _execute_autonomous_task(task)
            
            if task_result["success"]:
                thinking_steps[-1]["content"] += f"\n‚úÖ Task completed successfully"
                thinking_steps[-1]["status"] = "completed"
                tasks_completed.append(task["id"])
            else:
                thinking_steps[-1]["content"] += f"\n‚ùå Task failed: {task_result.get('error', 'Unknown error')}"
                thinking_steps[-1]["status"] = "failed"
        
        # Step 5: Generate response
        thinking_steps.append({
            "step": "Response Generation",
            "content": "Synthesizing results and generating comprehensive response...",
            "status": "processing"
        })
        
        # Use existing chat function but with enhanced context
        chat_result = sophie_chat(user_message)
        
        thinking_steps[-1]["content"] += "\n‚úÖ Response generated with full context integration"
        thinking_steps[-1]["status"] = "completed"
        
        # Enhanced response with thinking process
        # Humaniser la r√©ponse finale avec le processus de pens√©e
        humanized_result = natural_communication.humanize_sophie_response(
            technical_response=str(chat_result.get("reply", "")),
            user_message=user_message,
            context={
                "thinking_process": thinking_steps,
                "tasks_executed": tasks_created,
                "autonomy_level": "high",
                "reasoning_mode": True
            }
        )
        
        return {
            **chat_result,
            "reply": humanized_result.get("humanized_text", chat_result.get("reply", "")),
            "thinking_process": thinking_steps,
            "tasks_created": tasks_created,
            "tasks_completed": tasks_completed,
            "autonomy_level": "high",
            "reasoning_type": "chain_of_thought",
            "execution_time": sum([1 for step in thinking_steps if step["status"] == "completed"]) * 0.5,
            "communication_metadata": {
                "tone": humanized_result.get("tone", "analytical"),
                "emotion": humanized_result.get("emotion", "focused"),
                "humanization_success": humanized_result.get("success", True),
                "reasoning_humanized": True
            }
        }
        
    except Exception as e:
        return {
            "reply": f"Erreur dans le processus de r√©flexion: {str(e)}",
            "thinking_process": [{"step": "Error", "content": str(e), "status": "failed"}],
            "success": False
        }

def _analyze_user_intent(message: str) -> Dict[str, Any]:
    """Analyze user intent with multiple categories"""
    message_lower = message.lower()
    
    # Define intent patterns
    intent_patterns = {
        "classification_request": ["code", "classification", "classifier", "nacre", "quel code"],
        "analysis_request": ["analyse", "analyser", "tendance", "statistique", "rapport", "donn√©es"],
        "help_request": ["aide", "help", "comment", "utiliser", "guide", "expliquer"],
        "task_management": ["t√¢che", "task", "todo", "faire", "g√©rer", "organiser"],
        "optimization": ["optimiser", "am√©liorer", "mieux", "efficace", "performance"],
        "troubleshooting": ["probl√®me", "erreur", "bug", "issue", "panne", "dysfonction"],
        "exploration": ["explorer", "d√©couvrir", "voir", "montrer", "quoi", "que"],
        "conversation": ["bonjour", "salut", "hello", "test", "√ßa va"]
    }
    
    # Score each intent
    intent_scores = {}
    for intent, keywords in intent_patterns.items():
        score = sum(1 for keyword in keywords if keyword in message_lower)
        if score > 0:
            intent_scores[intent] = score
    
    # Determine primary intent
    if intent_scores:
        primary_intent = max(intent_scores, key=intent_scores.get)
        confidence = intent_scores[primary_intent] / len(message_lower.split())
    else:
        primary_intent = "general_inquiry"
        confidence = 0.5
    
    return {
        "primary_intent": primary_intent,
        "confidence": min(1.0, confidence * 3),  # Scale confidence
        "all_intents": intent_scores,
        "complexity": len(message.split()),
        "requires_data": primary_intent in ["classification_request", "analysis_request", "optimization"]
    }

def _gather_comprehensive_context() -> Dict[str, Any]:
    """Gather comprehensive context for decision making"""
    from .document_access import get_document_access
    from .nacre_dict import get_nacre_dict
    
    try:
        doc = get_document_access()
        nacre_dict = get_nacre_dict()
        
        return {
            "sources_count": 4,  # Dictionary, embeddings, patterns, memory
            "nacre_codes": len(nacre_dict.entries) if nacre_dict else 1571,
            "embeddings_ready": True,
            "memory_items": 50,  # Approximate
            "learning_examples": 100  # Approximate
        }
    except Exception:
        return {
            "sources_count": 0,
            "nacre_codes": 0,
            "embeddings_ready": False,
            "memory_items": 0,
            "learning_examples": 0
        }

def _plan_autonomous_tasks(message: str, intent_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
    """Plan autonomous tasks based on user intent"""
    tasks = []
    intent = intent_analysis["primary_intent"]
    
    # Generate task ID
    import time
    task_id_base = int(time.time() * 1000)
    
    if intent == "classification_request":
        tasks.append({
            "id": f"classify_{task_id_base}",
            "name": "NACRE Classification",
            "description": "Analyze and classify the user's request using NACRE codes",
            "type": "classification",
            "priority": "high",
            "estimated_duration": 2.0
        })
        
        tasks.append({
            "id": f"validate_{task_id_base}",
            "name": "Validation Check",
            "description": "Cross-validate classification results for accuracy",
            "type": "validation",
            "priority": "medium",
            "estimated_duration": 1.0
        })
    
    elif intent == "analysis_request":
        tasks.append({
            "id": f"data_analysis_{task_id_base}",
            "name": "Data Analysis",
            "description": "Perform comprehensive data analysis on available datasets",
            "type": "analysis",
            "priority": "high",
            "estimated_duration": 3.0
        })
        
        tasks.append({
            "id": f"insights_{task_id_base}",
            "name": "Generate Insights",
            "description": "Extract actionable insights from analysis results",
            "type": "insight_generation",
            "priority": "high",
            "estimated_duration": 2.0
        })
    
    elif intent == "optimization":
        tasks.append({
            "id": f"optimize_{task_id_base}",
            "name": "Process Optimization",
            "description": "Identify and suggest process improvements",
            "type": "optimization",
            "priority": "medium",
            "estimated_duration": 2.5
        })
    
    elif intent == "help_request":
        tasks.append({
            "id": f"help_{task_id_base}",
            "name": "Generate Help Content",
            "description": "Create comprehensive help and guidance content",
            "type": "help_generation",
            "priority": "medium",
            "estimated_duration": 1.5
        })
    
    # Always add a context enrichment task
    tasks.append({
        "id": f"context_{task_id_base}",
        "name": "Context Enrichment",
        "description": "Gather additional context to enhance response quality",
        "type": "context_enrichment",
        "priority": "low",
        "estimated_duration": 1.0
    })
    
    return tasks

def _execute_autonomous_task(task: Dict[str, Any]) -> Dict[str, Any]:
    """Execute an autonomous task"""
    try:
        task_type = task["type"]
        
        if task_type == "classification":
            # Simulate classification task
            return {
                "success": True,
                "result": "Classification analysis completed",
                "data": {"confidence": 0.85, "codes_analyzed": 5}
            }
        
        elif task_type == "validation":
            # Simulate validation task
            return {
                "success": True,
                "result": "Validation checks passed",
                "data": {"accuracy": 0.92, "consistency": 0.88}
            }
        
        elif task_type == "analysis":
            # Simulate data analysis
            return {
                "success": True,
                "result": "Data analysis completed",
                "data": {"patterns_found": 3, "anomalies": 1, "trends": 2}
            }
        
        elif task_type == "insight_generation":
            # Simulate insight generation
            return {
                "success": True,
                "result": "Insights generated",
                "data": {"actionable_insights": 4, "recommendations": 6}
            }
        
        elif task_type == "optimization":
            # Simulate optimization analysis
            return {
                "success": True,
                "result": "Optimization opportunities identified",
                "data": {"improvements": 3, "efficiency_gain": 15}
            }
        
        elif task_type == "help_generation":
            # Simulate help content generation
            return {
                "success": True,
                "result": "Help content generated",
                "data": {"sections": 5, "examples": 8}
            }
        
        elif task_type == "context_enrichment":
            # Simulate context gathering
            return {
                "success": True,
                "result": "Context enriched",
                "data": {"additional_sources": 2, "relevance_score": 0.78}
            }
        
        else:
            return {
                "success": False,
                "error": f"Unknown task type: {task_type}"
            }
            
    except Exception as e:
        return {
            "success": False,
            "error": f"Task execution failed: {str(e)}"
        }

def sophie_execute_agentic_action(action_type: str, parameters: Dict[str, Any]) -> Dict[str, Any]:
    """Execute autonomous agentic actions based on user requests"""
    
    try:
        if action_type == "analyze_patterns":
            return _analyze_classification_patterns(parameters)
        elif action_type == "detect_anomalies":
            return _detect_classification_anomalies(parameters)
        elif action_type == "optimize_classifications":
            return _suggest_classification_optimizations(parameters)
        elif action_type == "explain_code":
            return _explain_nacre_code(parameters)
        elif action_type == "compare_codes":
            return _compare_nacre_codes(parameters)
        elif action_type == "chain_of_thought":
            return sophie_chat_with_thinking(parameters.get("message", ""))
        else:
            return {
                "success": False,
                "error": f"Action type '{action_type}' not recognized",
                "available_actions": [
                    "analyze_patterns", "detect_anomalies", "optimize_classifications",
                    "explain_code", "compare_codes", "chain_of_thought"
                ]
            }
    except Exception as e:
        return {
            "success": False,
            "error": f"Error executing agentic action: {str(e)}",
            "action_type": action_type
        }

def _analyze_classification_patterns(parameters: Dict[str, Any]) -> Dict[str, Any]:
    """Analyze classification patterns autonomously"""
    from .document_access import get_document_access
    
    doc = get_document_access()
    
    # Get recent classifications for pattern analysis
    recent_examples = doc.search_training_examples("", limit=50)
    
    if not recent_examples:
        return {
            "success": True,
            "analysis": "Aucune donn√©e d'apprentissage disponible pour l'analyse des patterns.",
            "recommendations": ["Commencez par classifier quelques achats pour permettre l'analyse des patterns."]
        }
    
    # Analyze patterns
    code_frequency = {}
    supplier_patterns = {}
    account_patterns = {}
    
    for example in recent_examples:
        code = example.get('code', '')
        context = example.get('context', {})
        supplier = context.get('fournisseur', '')
        account = context.get('compte', '')
        
        if code:
            code_frequency[code] = code_frequency.get(code, 0) + 1
        if supplier and code:
            if supplier not in supplier_patterns:
                supplier_patterns[supplier] = {}
            supplier_patterns[supplier][code] = supplier_patterns[supplier].get(code, 0) + 1
        if account and code:
            if account not in account_patterns:
                account_patterns[account] = {}
            account_patterns[account][code] = account_patterns[account].get(code, 0) + 1
    
    # Generate insights
    most_common_codes = sorted(code_frequency.items(), key=lambda x: x[1], reverse=True)[:5]
    
    insights = [
        f"**Codes les plus utilis√©s :** {', '.join([f'{code} ({count}x)' for code, count in most_common_codes])}",
        f"**Fournisseurs analys√©s :** {len(supplier_patterns)} fournisseurs distincts",
        f"**Comptes comptables :** {len(account_patterns)} comptes distincts"
    ]
    
    recommendations = [
        "Standardiser les classifications des fournisseurs r√©currents",
        "Cr√©er des r√®gles automatiques pour les comptes comptables fr√©quents",
        "Valider la coh√©rence des codes les plus utilis√©s"
    ]
    
    return {
        "success": True,
        "analysis": "Analyse des patterns de classification termin√©e.",
        "insights": insights,
        "recommendations": recommendations,
        "data": {
            "total_examples": len(recent_examples),
            "unique_codes": len(code_frequency),
            "unique_suppliers": len(supplier_patterns),
            "unique_accounts": len(account_patterns)
        }
    }

def _detect_classification_anomalies(parameters: Dict[str, Any]) -> Dict[str, Any]:
    """Detect classification anomalies autonomously"""
    from .document_access import get_document_access
    
    doc = get_document_access()
    recent_examples = doc.search_training_examples("", limit=100)
    
    if not recent_examples:
        return {
            "success": True,
            "anomalies": [],
            "message": "Aucune donn√©e disponible pour la d√©tection d'anomalies."
        }
    
    anomalies = []
    
    # Detect low confidence classifications
    for example in recent_examples:
        confidence = example.get('confidence', 100)
        code = example.get('code', '')
        label = example.get('label', '')
        
        if confidence < 60:
            anomalies.append({
                "type": "Confiance faible",
                "description": f"Classification '{label}' ‚Üí {code} avec confiance {confidence}%",
                "severity": "medium",
                "recommendation": "V√©rifier et ajuster cette classification"
            })
    
    # Detect inconsistent supplier mappings
    supplier_codes = {}
    for example in recent_examples:
        context = example.get('context', {})
        supplier = context.get('fournisseur', '')
        code = example.get('code', '')
        
        if supplier and code:
            if supplier not in supplier_codes:
                supplier_codes[supplier] = set()
            supplier_codes[supplier].add(code)
    
    for supplier, codes in supplier_codes.items():
        if len(codes) > 3:  # Supplier with many different codes might be inconsistent
            anomalies.append({
                "type": "Incoh√©rence fournisseur",
                "description": f"Fournisseur '{supplier}' associ√© √† {len(codes)} codes diff√©rents",
                "severity": "high",
                "recommendation": f"Standardiser les classifications pour {supplier}"
            })
    
    return {
        "success": True,
        "anomalies": anomalies,
        "total_checked": len(recent_examples),
        "anomalies_found": len(anomalies)
    }

def _suggest_classification_optimizations(parameters: Dict[str, Any]) -> Dict[str, Any]:
    """Suggest classification optimizations autonomously"""
    
    optimizations = [
        {
            "category": "Pr√©cision",
            "suggestion": "Enrichir le contexte des classifications",
            "description": "Ajouter plus d'informations sur les fournisseurs et montants pour am√©liorer la pr√©cision",
            "impact": "high",
            "effort": "medium"
        },
        {
            "category": "Coh√©rence", 
            "suggestion": "Standardiser les codes par fournisseur",
            "description": "Cr√©er des r√®gles automatiques pour les fournisseurs r√©currents",
            "impact": "high",
            "effort": "low"
        },
        {
            "category": "Automatisation",
            "suggestion": "Augmenter le seuil de confiance automatique",
            "description": "Passer de 80% √† 85% de confiance pour les classifications automatiques",
            "impact": "medium",
            "effort": "low"
        },
        {
            "category": "Qualit√©",
            "suggestion": "Impl√©menter la validation crois√©e",
            "description": "V√©rifier la coh√©rence compte comptable ‚Üî code NACRE",
            "impact": "high",
            "effort": "high"
        }
    ]
    
    return {
        "success": True,
        "optimizations": optimizations,
        "priority_order": ["Coh√©rence", "Pr√©cision", "Automatisation", "Qualit√©"],
        "estimated_improvement": "15-25% d'am√©lioration de la pr√©cision globale"
    }

def _explain_nacre_code(parameters: Dict[str, Any]) -> Dict[str, Any]:
    """Explain a NACRE code autonomously"""
    from .nacre_dict import get_nacre_dict
    
    code = parameters.get('code', '').upper()
    if not code:
        return {
            "success": False,
            "error": "Code NACRE non sp√©cifi√©"
        }
    
    nacre_dict = get_nacre_dict()
    
    # Search for the code
    candidates = [entry for entry in nacre_dict.entries if entry.code == code]
    
    if not candidates:
        return {
            "success": False,
            "error": f"Code NACRE '{code}' non trouv√© dans le dictionnaire"
        }
    
    entry = candidates[0]
    
    return {
        "success": True,
        "code": entry.code,
        "category": entry.category,
        "keywords": entry.keywords,
        "explanation": f"Le code {entry.code} correspond √† '{entry.category}' et couvre les achats li√©s aux mots-cl√©s : {', '.join(entry.keywords[:10])}",
        "usage_context": "Ce code est utilis√© pour classifier les achats dans cette cat√©gorie sp√©cifique."
    }

def _compare_nacre_codes(parameters: Dict[str, Any]) -> Dict[str, Any]:
    """Compare NACRE codes autonomously"""
    from .nacre_dict import get_nacre_dict
    
    codes = parameters.get('codes', [])
    if len(codes) < 2:
        return {
            "success": False,
            "error": "Au moins 2 codes requis pour la comparaison"
        }
    
    nacre_dict = get_nacre_dict()
    comparisons = []
    
    for code in codes:
        code = code.upper()
        candidates = [entry for entry in nacre_dict.entries if entry.code == code]
        if candidates:
            entry = candidates[0]
            comparisons.append({
                "code": entry.code,
                "category": entry.category,
                "keywords": entry.keywords[:5],  # Limit for comparison
                "found": True
            })
        else:
            comparisons.append({
                "code": code,
                "found": False
            })
    
    # Find common keywords
    if len([c for c in comparisons if c.get('found')]) >= 2:
        all_keywords = []
        for comp in comparisons:
            if comp.get('found'):
                all_keywords.extend(comp.get('keywords', []))
        
        from collections import Counter
        keyword_counts = Counter(all_keywords)
        common_keywords = [kw for kw, count in keyword_counts.items() if count > 1]
    else:
        common_keywords = []
    
    return {
        "success": True,
        "comparisons": comparisons,
        "common_keywords": common_keywords,
        "analysis": f"Comparaison de {len(codes)} codes NACRE effectu√©e",
        "similarities": f"{len(common_keywords)} mots-cl√©s communs trouv√©s" if common_keywords else "Aucun mot-cl√© commun identifi√©"
    }

def sophie_last_debug() -> Dict[str, Any]:
    mem = _load_memory()
    return mem.get("last_debug", {"received": False, "interpreted": False, "used_fallback": False})
